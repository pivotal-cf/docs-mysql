---
title: Troubleshooting VMware Tanzu SQL with MySQL for VMs
owner: MySQL
---

<strong><%= modified_date %></strong>

This topic provides operators with basic instructions for troubleshooting on-demand <%= vars.product_full %>.
For information about temporary <%= vars.product_short %> service interruptions, see
<a href="./upgrade.html#interruptions">Service Interruptions</a>.

## <a id="errors"></a> Troubleshoot Errors

This section provides information on how to troubleshoot specific errors or error messages.

### <a id="x-product"></a> Common Services Errors

The following errors occur in multiple services:

+ [Failed Installation](#install-fail)
+ [Cannot Create or Delete Service Instances](#cannot-create-delete)
+ [Broker Request Timeouts](#timeouts)
+ [Instance Does Not Exist](#instance-not-exist)
+ [Cannot Bind to or Unbind from Service Instances](#cannot-bind)
+ [Cannot Connect to a Service Instance](#cannot-connect)
+ [Upgrade All Service Instances Errand Fails](#upgrade-all-fails)
+ [Missing Logs and Metrics](#missing-logs)

<a name="install-fail"></a>

<div>

  <table class="nice">
    <style>
      main table {
        table-layout: fixed;
      }
    </style>
  <col width="20%">
  <col width="80%">
  <tr>
  <th colspan="2" style="text-align: left;"> <br>
    Failed Installation
  <br><br></th>
  </tr>

  <tr>
    <th>Symptom</th>
    <td><%= vars.product_short %> fails to install.</td>
  </tr>

  <tr>
    <th>Cause</th>
    <td>Reasons for a failed installation include:
    <ul>
    <li>
    Certificate issues: The on-demand broker (ODB) requires valid certificates.
    </li>
    <li>Deploy fails. This could be due to a variety of reasons.
    </li>
    <li>Networking problems: </li>
    <ul>
    <li>Cloud Foundry cannot reach the <%= vars.product_short %> broker</li>
    <li>Cloud Foundry cannot reach the service instances</li>
    <li>The service network cannot access the BOSH director </li>
    </ul>
    <li>The Register broker errand fails.</li>
    <li>The smoke test errand fails.</li>
    <li>
    Resource sizing issues: These occur when the resource sizes selected for a
    given plan are less than <%= vars.product_short %> requires to function.
    </li>
    <li>Other service-specific issues.</li>
    </ul></td>
  </tr>

  <tr>
    <th style="vertical-align: top; padding-top: 1em;">Solution</th>
    <td>To troubleshoot:
    <ul>
    <li>Certificate issues: Ensure that your certificates are valid and generate new ones if necessary.
    To generate new certificates, contact <a href="https://tanzu.vmware.com/support">Support</a>.</li>

    <li>Deploy fails: View the logs using <%= vars.ops_manager %> to determine why the deploy is failing.</li>

    <li>Networking problems: For how to troubleshoot, see <a href="#network">Networking problems</a>. </li>

    <li>Register broker errand fails: For how to troubleshoot, see <a href="#register-broker">Register broker errand</a>.</li>

    <li>Resource sizing issues: Check your resource configuration in <%= vars.ops_manager %> and ensure that the
    configuration matches that recommended by the service.</li>
    </ul></td>
  </tr>

</table>
</div>

<a name="cannot-create-delete"></a>

<div>

  <table class="nice">
    <style>
      main table {
        table-layout: fixed;
      }
    </style>
  <col width="20%">
  <col width="80%">
  <tr>
  <th colspan="2" style="text-align: left;"> <br>
    Cannot Create or Delete Service Instances
  <br><br></th>
  </tr>

  <tr>
    <th>Symptom</th>
    <td>If developers report errors such as:
		<pre class="terminal">Instance provisioning failed: There was a problem completing your request. Please contact your operations team providing the following information: service: redis-acceptance, service-instance-guid: ae9e232c-0bd5-4684-af27-1b08b0c70089, broker-request-id: 63da3a35-24aa-4183-aec6-db8294506bac, task-id: 442, operation: create</pre></td>
  </tr>

  <tr>
    <th>Cause</th>
    <td>Reasons include:
    <ul>
      <li>Problems with the deployment manifest</li>
      <li>Authentication errors</li>
      <li>Network errors</li>
      <li>Quota errors</li>
    </ul></td>
  </tr>

  <tr>
    <th style="vertical-align: top; padding-top: 1em;">Solution</th>
    <td>To troubleshoot:
        <ol>
        <li>
        <p>
        If the BOSH error shows a problem with the deployment manifest, open the
        manifest in a text editor to inspect it.
        </p>
        </li>
        <li>
        <p>
        To continue troubleshooting,
        <a href="https://docs.pivotal.io/pivotalcf/customizing/trouble-advanced.html#log-in">Log in to BOSH</a>
        and target the Tanzu SQL for VMs instance using the instructions
        on <a href="#parse-error">parsing a Cloud Foundry error message</a>.
        </p>
        </li>
        <li>
        <p>
        Retrieve the BOSH task ID from the error message and run the following command:
        </p>
        <code>bosh task TASK-ID</code>
        </li>
        <li>
        <p>
        If you need more information, <a href="#access-broker">access the broker logs</a> and
        use the <code>broker-request-id</code> from the previous error message to search the logs for
        more information. Search for:
        </p>
        </li>
        <ul>
        <li><a href="#auth">Authentication errors</a></li>
        <li><a href="#network">Network errors</a></li>
        <li><a href="#quotas">Quota errors</a></li>
        </ul>
        </ol></td>
  </tr>

</table>
</div>

<a name="timeouts"></a>

<div>

  <table class="nice">
    <style>
      main table {
        table-layout: fixed;
      }
    </style>
  <col width="20%">
  <col width="80%">
  <tr>
  <th colspan="2" style="text-align: left;"> <br>
    Broker Request Timeouts
  <br><br></th>
  </tr>

  <tr>
    <th>Symptom</th>
    <td>If developers report errors such as:
		<pre class="terminal">Server error, status code: 504, error code: 10001, message: The request to the service broker timed out: https://BROKER-URL/v2/service_instances/e34046d3-2379-40d0-a318-d54fc7a5b13f/service_bindings/aa635a3b-ef6d-41c3-a23f-55752f3f651b</pre></td>
  </tr>

  <tr>
    <th>Cause</th>
    <td>Cloud Foundry might not be connected to the service broker, or there might be a large number of queued tasks.</td>
  </tr>

  <tr>
    <th style="vertical-align: top; padding-top: 1em;">Solution</th>
    <td>To troubleshoot:
        <ol>
        <li>
        Confirm that Cloud Foundry (CF) is <a href="#network">connected to the service broker</a>.
        </li>
        <li>
        Check the BOSH queue size:
        <ol>
        <li>Log in to BOSH as an admin.</li>
        <li>Run <code>bosh tasks</code></li>
        </ol>
    If there are a large number of queued tasks, the system might be under too much load.
        BOSH is configured with two workers and one status worker, which might not be
        sufficient resources for the level of load.
        </li>
        <li>
        If the task queue is long, advise the app developers to try again once the system is under less of a load.
        </li>
        </ol></td>
  </tr>

</table>
</div>

<a name="instance-not-exist"></a>

<div>

  <table class="nice">
    <style>
      main table {
        table-layout: fixed;
      }
    </style>
  <col width="20%">
  <col width="80%">
  <tr>
  <th colspan="2" style="text-align: left;"> <br>
    Instance Does Not Exist
  <br><br></th>
  </tr>

  <tr>
    <th>Symptom</th>
    <td>If developers report errors such as:
		<pre class="terminal">Server error, status code: 502, error code: 10001, message: Service broker error: instance does not exist</pre></td>
  </tr>

  <tr>
    <th>Cause</th>
    <td>The instance might have been deleted.</td>
  </tr>

  <tr>
    <th style="vertical-align: top; padding-top: 1em;">Solution</th>
    <td>To troubleshoot:
        <ol>
        <li>
        <p>
        Confirm that the Tanzu SQL for VMs instance exists in BOSH and
        obtain the GUID CF by running:
        </p>
        <code>cf service MY-INSTANCE --guid</code>
        </li>
        <li>
        <p>
        Using the GUID that you obtained previously, run:
        </p>
        <code>bosh -d service-instance_GUID vms</code>
        </li>
        </ol>

		<p>
		If the BOSH deployment is not found, it has been deleted from BOSH.
		Contact Support for further assistance.
		</p></td>
  </tr>

</table>
</div>

<a name="cannot-bind"></a>

<div>

  <table class="nice">
    <style>
      main table {
        table-layout: fixed;
      }
    </style>
  <col width="20%">
  <col width="80%">
  <tr>
  <th colspan="2" style="text-align: left;"> <br>
    Cannot Bind to or Unbind from Service Instances
  <br><br></th>
  </tr>

  <tr>
    <th>Symptom</th>
    <td>If developers report errors such as:
    <pre class="terminal">Server error, status code: 502, error code: 10001, message: Service broker error: There was a problem completing your request. Please contact your operations team providing the following information: service: example-service, service-instance-guid: 8d69de6c-88c6-4283-b8bc-1c46103714e2, broker-request-id: 15f4f87e-200a-4b1a-b76c-1c4b6597c2e1, operation: bind</pre></td>
  </tr>

  <tr>
    <th>Cause</th>
    <td>This might be due to authentication or network errors.</td>
  </tr>

  <tr>
    <th style="vertical-align: top; padding-top: 1em;">Solution</th>
    <td>To find out the exact issue with the binding process:
    <ol>
    <li>
    <p>
      <a href="#access-broker">Access the service broker logs</a>.
    </p>
    </li>
    <li>
    <p>
      Search the logs for the <code>broker-request-id</code> string listed in the error message.
    </p>
    </li>
    <li>
    <p>
      Check for:
    </p>
    </li>
    <ul>
    <li><a href="#auth">Authentication errors</a></li>
    <li><a href="#network">Network errors</a></li>
    </ul>
    <li>
    <p>
    Contact Support for further assistance if you are unable to resolve the problem.
    </p>
    </li>
    </ol></td>
  </tr>

</table>
</div>

<a name="cannot-connect"></a>

<div>

  <table class="nice">
    <style>
      main table {
        table-layout: fixed;
      }
    </style>
  <col width="20%">
  <col width="80%">
  <tr>
  <th colspan="2" style="text-align: left;"> <br>
    Cannot Connect to a Service Instance
  <br><br></th>
  </tr>

  <tr>
    <th>Symptom</th>
    <td>Developers report that their app cannot use service instances that they have
    successfully created and bound.</td>
  </tr>

  <tr>
    <th>Cause</th>
    <td>The error might originate from the service or be network related.</td>
  </tr>

  <tr>
    <th style="vertical-align: top; padding-top: 1em;">Solution</th>
    <td>To solve this issue, ask the user to send application logs that show the connection error.
    If the error originates from the service, then follow <%= vars.product_short %>-specific instructions.
    If the issue appears to be network-related, then:
    <ol>
    <li>
    <p>
    Check that <a href="https://docs.pivotal.io/application-service/operating/app-sec-groups.html"/>application security groups</a>
    are configured correctly.
    Access can be configured for the service network that the tile is deployed to.
    </p>
    </li>
    <li>
    <p>
    Ensure that the network the <%= vars.app_runtime_abbr %> tile is deployed
    to has network access to the service network. You can find the network definition
    for this service network in the BOSH Director tile.
    </p>
    </li>
    <li>
    <p>
    In <%= vars.ops_manager %> go into the service tile and see the service network that is
    configured in the **Networks** tab.
    </p>
    </li>
    <li>
    <p>
    In <%= vars.ops_manager %> go into the <%= vars.app_runtime_abbr %> tile and see the network it is assigned to.
    Make sure that these networks can access each other.
    </p>
    </li>
    </ol></td>
  </tr>

</table>
</div>

<p class="note"><strong>Note:</strong>
  Service instances can also become temporarily inaccessible during upgrades and VM or network failures.
  See <a href="./upgrade.html#interruptions">Service Interruptions</a> for more information.
</p>

<a name="upgrade-all-fails"></a>

<div>

  <table class="nice">
    <style>
      main table {
        table-layout: fixed;
      }
    </style>
  <col width="20%">
  <col width="80%">
  <tr>
  <th colspan="2" style="text-align: left;"> <br>
    Upgrade All Service Instances Errand Fails
  <br><br></th>
  </tr>

  <tr>
    <th>Symptom</th>
    <td>The <a href="#upgrade-all"><code>upgrade-all-service-instances</code></a> errand fails.</td>
  </tr>

  <tr>
    <th>Cause</th>
    <td>There might be a problem with a particular instance.</td>
  </tr>

  <tr>
    <th style="vertical-align: top; padding-top: 1em;">Solution</th>
    <td>To troubleshoot:
    <ol>
    <li>Look at the errand output in the <%= vars.ops_manager %> log.</li>

    <li>If an instance has failed to upgrade, debug and fix it before running the errand again
    to prevent any failure issues from spreading to other on-demand instances.</li>

    <li>After the <%= vars.ops_manager %> log no longer lists the deployment as <code>failing</code>,
    <a href="#upgrade-all">re-run the errand</a> to upgrade the rest of the instances.</li>
    </ol>
</td>
  </tr>

</table>
</div>

<a name="missing-logs"></a>

<div>

  <table class="nice">
    <style>
      main table {
        table-layout: fixed;
      }
    </style>
  <col width="20%">
  <col width="80%">
  <tr>
  <th colspan="2" style="text-align: left;"> <br>
    Missing Logs and Metrics
  <br><br></th>
  </tr>

  <tr>
    <th>Symptom</th>
    <td>No logs are being emitted by the on-demand broker.</td>
  </tr>

  <tr>
    <th>Cause</th>
    <td>Syslog might not be configured correctly, or you might have network access issues.</td>
  </tr>

  <tr>
    <th style="vertical-align: top; padding-top: 1em;">Solution</th>
    <td>To troubleshoot:
    <ol>
    <li>
    <p>
    Ensure you have configured syslog for the tile.
    </p>
    </li>
    <li> Check that your syslog forwarding address is correct in <%= vars.ops_manager %>.</li>
    <li>
    <p>
    Ensure that you have network connectivity between the networks that the tile
    is using and the syslog destination.
    If the destination is external, you need to use the <a href="https://docs.pivotal.io/svc-sdk/odb/tile.html#public-ip">public ip</a>
    VM extension feature available in your <%= vars.ops_manager %> tile configuration settings.
    </p>
    </li>
    <li>
    <p>
    Verify that Loggregator is emitting metrics:
    </p>
    <ol>
    <li>
    <p>
    Install the <code>cf log-cache</code> plug-in.
    For instructions, see the <a href="https://github.com/cloudfoundry/log-cache-cli">Log Cache CLI Plug-in</a>
    GitHub repository.
    </p>
    </li>
    <li>
    <p>
    Find the GUID for your service instance by running:
    </p>
    <pre><code>cf service SERVICE-INSTANCE --guid</code></pre>
    </li>
    <li>
    <p>
    Find logs from your service instance by running:
    </p>
    <pre><code>cf log-stream | grep "SERVICE-GUID"</code></pre>
    </li>
    <li>If no metrics appear within five minutes, verify that the broker network has access
    to the Loggregator system on all required ports.</li>
    </ol>
    </li>
    <li>If you are unable to resolve the issue, contact <a href="#support">Support</a>. </li>
    </ol>

</td>
  </tr>

</table>
</div>


### <a id="l-f-errors"></a> Leader-Follower Service Instance Errors

This section provides solutions for the following errands:

+ [Unable to Determine Leader and Follower](#unable-to-determine)
+ [Both Leader and Follower Instances Are Writable](#both-writable)
+ [Both Leader and Follower Instances Are Read-Only](#both-read-only)

<a name="unable-to-determine"></a>

<div>

  <table class="nice">
    <style>
      main table {
        table-layout: fixed;
      }
    </style>
  <col width="20%">
  <col width="80%">
  <tr>
  <th colspan="2" style="text-align: left;"> <br>
    Unable to Determine Leader and Follower
  <br><br></th>
  </tr>

  <tr>
    <th>Symptom</th>
    <td>This problem happens when the <code>configure-leader-follower</code>
    errand fails because it cannot determine the VM roles. <br><br>

    The <code>configure-leader-follower</code> errand exits with <code>1</code>
    and the errand logs contain the following:

    <pre class="terminal">$ Unable to determine leader and follower based on transaction history.</pre>
</td>
  </tr>

  <tr>
    <th>Cause</th>
    <td>Something has happened to the instances, such as a failure or manual intervention.
      As a result, there is not enough information available to determine the correct state
      and topology without operator intervention to resolve the issue.
</td>
  </tr>

  <tr>
    <th style="vertical-align: top; padding-top: 1em;">Solution</th>
    <td>Use the <code>inspect</code> errand to determine which instance can be the leader. Then, using the
    <a href="./about-leader-follower.html#errands">orchestration</a>
    errands and backup/restore, you can put the service instance into a safe topology, and then rerun the
    <code>configure-leader-follower</code> errand. This is shown in the following example.<br><br>
    This example shows one outcome that the <code>inspect</code> errand can return: <br>

    <ol>
      <li>Use the
        <code>inspect</code>
        errand to retrieve relevant information about the two VMs:
        <pre class="terminal">$ bosh -e my-env -d my-dep run-errand inspect
      [...]
      Instance   mysql/4ecad54b-0704-47eb-8eef-eb228cab9724
      Exit Code  0
      Stdout     -
      Stderr   2017/12/11 18:25:54 Started executing command: inspect
               2017/12/11 18:25:54 Started GET https<span>:</span>//127.0.0.1:8443/status
               2017/12/11 18:25:54
               Has Data: false
               Read Only: true
               GTID Executed: 1d774323-de9e-11e7-be01-42010a001014:1-25
               Replication Configured: false
      Instance   mysql/e0b94ade-0114-4d49-a929-ce1616d8beda
      Exit Code  0
      Stdout     -
      Stderr   2017/12/11 18:25:54 Started executing command: inspect
               2017/12/11 18:25:54
               Started GET https<span>:</span>//127.0.0.1:8443/status
               2017/12/11 18:25:54
               Has Data: true
               Read Only: true
               GTID Executed: 1d774323-de9e-11e7-be01-42010a001014:1-25
               Replication Configured: true
      2 errand(s)
      Succeeded</pre>

        In the previous scenario, the first instance is missing data but does not have replication configured. The second instance has data, and also has replication configured. The following instructions resolve this by copying data to the first instance, and
        resuming replication.</li>
      <li>Take a backup of the second instance using the
        <a href="./backup-mysqldump.html#create-backup">Create a <%= vars.product_short %> Logical Backup</a>
        steps.</li>
      <li>Restore the backup artifact to the first instance using the
        <a href="./backup-mysqldump.html#restore-backup">Restore from a <%= vars.product_short %> Logical Backup</a>
        steps.<br>
        At this point, the instances have equivalent data.</li>
      <li>
        Run the <code>configure-leader-follower</code> errand to reconfigure replication:
        <pre class="terminal">bosh -e ENVIRONMENT -d DEPLOYMENT &#92;
          run-errand configure-leader-follower &#92;
          --instance=mysql/GUID-OF-LEADER</pre>
        For example:

        <pre class="terminal">$ bosh -e my-env -d my-dep &#92;
          run-errand configure-leader-follower &#92;
          --instance=mysql/4ecad54b-0704-47eb-8eef-eb228cab9724</pre>
      </li>
    </ol></td>
  </tr>

</table>
</div>

<a name="both-writable"></a>

<div>

  <table class="nice">
    <style>
      main table {
        table-layout: fixed;
      }
    </style>
  <col width="20%">
  <col width="80%">
  <tr>
  <th colspan="2" style="text-align: left;"> <br>
    Both Leader and Follower Instances Are Writable
  <br><br></th>
  </tr>

  <tr>
    <th>Symptom</th>
    <td>
    This problem happens when the <code>configure-leader-follower</code> errand fails because both VMs are writable and the VMs might hold differing data. <br><br>
    The <code>configure–leader-follower</code> errand exits with <code>1</code>
    and the errand logs contain the following:

    <pre class="terminal">$ Both mysql instances are writable. Please ensure no divergent data and set one instance to read-only mode.</pre>
</td>
  </tr>

  <tr>
    <th>Cause</th>
    <td><%= vars.product_short %> tries to ensure that there is only one writable instance of the
      leader-follower pair at any given time. However, in certain situations, such as
      network partitions, or manual intervention outside of the provided bosh
      errands, it is possible for both instances to be writable. <br><br>
      The service instances remain in this state until an operator resolves the issue
      to ensure that the correct instance is promoted and reduce the potential for data divergence.</td>
  </tr>

  <tr>
    <th style="vertical-align: top; padding-top: 1em;">Solution</th>
    <td>
    <ol>
        <li>
          Use the
          <code>inspect</code> errand to retrieve the GTID Executed set for each VM:

          <pre class="terminal">$ bosh -e my-env -d my-dep run-errand inspect
        [...]
        Instance   mysql/4ecad54b-0704-47eb-8eef-eb228cab9724
        Exit Code  0
        Stdout     -
        Stderr     2017/12/11 18:25:54 Started executing command: inspect
                 2017/12/11 18:25:54 Started GET https<span>:</span>127.0.0.1:8443/status
                 2017/12/11 18:25:54
                 Has Data: true
                 Read Only: false
                 GTID Executed: 1d774323-de9e-11e7-be01-42010a001014:1-23
                 Replication Configured: false<br /><br />
        Instance   mysql/e0b94ade-0114-4d49-a929-ce1616d8beda
        Exit Code  0
        Stdout     -
        Stderr     2017/12/11 18:25:54 Started executing command: inspect
                 2017/12/11 18:25:54 Started GET https<span>:</span>127.0.0.1:8443/status
                 2017/12/11 18:25:54
                 Has Data: true
                 Read Only: false
                 GTID Executed: 1d774323-de9e-11e7-be01-42010a001014:1-25
                 Replication Configured: false<br /><br />
        2 errand(s)<br />
        Succeeded
      </pre>
          If the GTID Executed sets for both instances are the same, continue to Step 2. If they are different, continue to Step 4.</li>
        <li>Look at the value of GTID Executed for both instances.
          <ul>
            <li>If the range after the GUID is equivalent, either instance can be made read-only, as described in Step 3.</li>
            <li>If one instance has a range that is a subset of the other, the instance with the subset must be made read-only, as described in Step 3.</li>
          </ul>
        </li>
        <li>Based on the information you gathered in the previous step, run the
          <code>make-read-only</code>
          errand to make the appropriate instance read-only:
          <pre><code>bosh -e ENVIRONMENT -d DEPLOYMENT &#92;
            run-errand make-read-only &#92;
            --instance=mysql/MYSQL-SUBSET-INSTANCE</code></pre>
          For example:
          <pre class="terminal">$ bosh -e my-env -d my-dep &#92;
              run-errand make-read-only &#92;
              --instance=mysql/e0b94ade-0114-4d49-a929-ce1616d8beda
            [...]
            succeeded</pre>
        </li>
        <li>If the GTID Executed sets are neither equivalent nor subsets, data has diverged and you must determine what data has diverged as part of the procedure:
          <ol>
            <li>Use the
              <code>make-read-only</code>
              errand to set both instances to read-only to prevent further data divergence.
              <pre><code>bosh -e ENVIRONMENT -d DEPLOYMENT &#92;
                run-errand make-read-only &#92;
                --instance=mysql/MYSQL-INSTANCE</code></pre>
              For example:
              <pre class="terminal">$ bosh -e my-env -d my-dep &#92;
                  run-errand make-read-only &#92;
                  --instance=mysql/e0b94ade-0114-4d49-a929-ce1616d8beda
                  [...]
                  succeeded</pre>
            </li>
            <li>Take a backup of both instances using the
              <a href="./backup-mysqldump.html#create-backup"> Create a <%= vars.product_short %> Logical Backup</a>
              steps.</li>
            <li>Manually inspect the data on each instance to determine the discrepancies and put the data on the instance that is further ahead&mdash;this instance has the higher GTID Executed set, and is the new leader.</li>
            <li>Migrate all appropriate data to the new leader instance.</li>
            <li>After putting all data on the leader, ssh onto the follower:
              <pre><code>bosh -e ENVIRONMENT -d DEPLOYMENT ssh mysql/GUID-OF-FOLLOWER</code></pre>
              For example:
              <pre class="terminal">$ bosh -e my-env -d my-dep ssh mysql/e0b94ade-0114-4d49-a929-ce1616d8beda</pre>
            </li>
            <li>Become root with the command
              <code>sudo su</code>.<br></li>
            <li>Stop the mysql process with the command
              <code>monit stop mysql</code>.</li>
            <li>Delete the data directory of the follower with the command
              <code>rm -rf /var/vcap/store/mysql</code>.</li>
            <li>Start the mysql process with the command
              <code>monit start mysql</code>.</li>
            <li>Use the
              <code>configure-leader-follower</code>
              errand to copy the leader data to the follower and resume replication:
              <pre><code>bosh -e ENVIRONMENT -d DEPLOYMENT &#92;
                run-errand configure-leader-follower &#92;
                --instance=mysql/GUID-OF-LEADER</code></pre>
              For example:
              <pre class="terminal">$ bosh -e my-env -d my-dep &#92;
                run-errand configure-leader-follower &#92;
                --instance=mysql/4ecad54b-0704-47eb-8eef-eb228cab9724</pre>
            </li>
          </ol>
        </li>
      </ol>
    </td>
  </tr>

</table>
</div>

<a name="both-read-only"></a>

<div>

  <table class="nice">
    <style>
      main table {
        table-layout: fixed;
      }
    </style>
  <col width="20%">
  <col width="80%">
  <tr>
  <th colspan="2" style="text-align: left;"> <br>
    Both Leader and Follower Instances Are Read-Only
  <br><br></th>
  </tr>

  <tr>
    <th>Symptom</th>
    <td>Developers report that apps cannot write to the database. In a leader-follower topology, the leader VM is writable and the follower VM is read-only.
    However, if both VMs are read-only, apps cannot write to the database.</td>
  </tr>

  <tr>
    <th>Cause</th>
    <td>This problem happens if the leader VM fails and the BOSH Resurrector is activated.
    When the leader is resurrected, it is set as read-only.</td>
  </tr>

  <tr>
    <th style="vertical-align: top; padding-top: 1em;">Solution</th>
    <td>
    <ol>
      <li>
        Use the
        <code>inspect</code>
        errand to confirm that both VMs are in a read-only state:
        <pre class="terminal">bosh -e ENVIRONMENT -d DEPLOYMENT run-errand inspect</pre>
      </li>
      <li>Examine the output and locate the information about the leader-follower
        <%= vars.product_short %> VMs:
        <pre class="terminal">
    Instance   mysql/4eexample54b-0704-47eb-8eef-eb2example724
    Exit Code  0
    Stdout     -
    Stderr     2017/12/11 18:25:54 Started executing command: inspect
             2017/12/11 18:25:54 Started GET https<span>:</span>999.0.0.1:8443/status
             2017/12/11 18:25:54
             Has Data: true
             Read Only: true
             GTID Executed: 1d779999-de9e-11e7-be01-42010a009999:1-23
             Replication Configured: true<br /><br />
    Instance   mysql/e0exampleade-0114-4d49-a929-cexample8beda
    Exit Code  0
    Stdout     -
    Stderr     2017/12/11 18:25:54 Started executing command: inspect
             2017/12/11 18:25:54 Started GET https<span>:</span>999.0.0.1:8443/status
             2017/12/11 18:25:54
             Has Data: true
             Read Only: true
             GTID Executed: 1d779999-de9e-11e7-be01-42010a009999:1-25
             Replication Configured: false<br /><br />
    2 errand(s)<br />
    Succeeded
    </pre>
      </li>
      <li>
        If Read Only is set to
        <code>true</code>
        for both VMs, make the leader writable using the following command:
        <pre class="terminal">bosh -e ENVIRONMENT -d DEPLOYMENT &#92;
          run-errand configure-leader-follower &#92;
          --instance=mysql/GUID-OF-LEADER</code>
        For example, if the second instance is the leader:
        <pre class="terminal">
        $ bosh -e my-env -d my-dep &#92;
          run-errand configure-leader-follower &#92;
          --instance=mysql/e0exampleade-0114-4d49-a929-cexample8beda
        </pre>
      </li>
    </ol>
   </td>
  </tr>

</table>
</div>

###<a id="apps-inoperable"></a>Inoperable App and Database Errors

This section provides a solution for the following errors:

+ [Persistent Disk is Full](#persistent-disk)
+ [Cannot Access Database Table](#access-table)

<a name="persistent-disk"></a>

<div>

  <table class="nice">
    <style>
      main table {
        table-layout: fixed;
      }
    </style>
  <col width="20%">
  <col width="80%">
  <tr>
  <th colspan="2" style="text-align: left;"> <br>
    Persistent Disk is Full
  <br><br></th>
  </tr>

  <tr>
    <th>Symptom</th>
    <td>Developers report that read, write, and cf CLI operations do not work.
    Developers cannot upgrade to a larger <%= vars.product_short %> service plan to free up disk space. <br><br>
    If your persistent disk is full, apps become inoperable.
    In this state, read, write, and Cloud Foundry Command-Line Interface (cf CLI) operations do not work.</td>
  </tr>

  <tr>
    <th>Cause</th>
    <td>This problem happens if your persistent disk is full.
    When you use the BOSH CLI to target your deployment, you see that instances are at 100% persistent disk usage. <br><br>
    Available disk space can be increased by deleting log files.
    After deleting logs, you can then upgrade to a larger <%= vars.product_short %> service plan.
    <br><br>
    You can also turn off binary logging before developers do large data uploads or if their
    databases have a high transaction volume.</td>
  </tr>

  <tr>
    <th style="vertical-align: top; padding-top: 1em;">Solution</th>
    <td>
    To resolve this issue, do one of the following:<br><br>
          <ul>
            <li><strong>If your persistent disk is already full,</strong> delete binary logs.
              See
              <a href="https://community.pivotal.io/s/article/mysql-for-pcf-hangs-when-server-vm-persistent-disk-is-full">MySQL for PCF hangs when server VM persistent disk is full</a>
              in the Knowledge Base.
              <p class="note warning"><strong>Warning:</strong>
                Deleting binary logs is a destructive procedure and can result in MySQL data loss.
                Only do this procedure with the assistance of <a href="https://tanzu.vmware.com/support">Support</a>.
              </p>
            </li>
            <li>
              <strong>If the majority of your persistent disk are binary logs but it is not currently full,</strong>
              turn off binary logging.
              See
              <a href="https://community.pivotal.io/s/article/turning-off-binary-logging">Binary Logs Filling up the Persistent Disk</a>
              in the Knowledge Base.
            </li>
            </ul>
            </td>
  </tr>

</table>
</div>

<a name="access-table"></a>

<div>

  <table class="nice">
    <style>
      main table {
        table-layout: fixed;
      }
    </style>
  <col width="20%">
  <col width="80%">
  <tr>
  <th colspan="2" style="text-align: left;"> <br>
    Cannot Access Database Table
  <br><br></th>
  </tr>

  <tr>
    <th>Symptom</th>
    <td>When you query an existing table, you see an error similar to
    the following:
    <pre class="terminal">ERROR 1146 (42S02): Table 'mysql.foobar' doesn't exist</pre></td>
  </tr>

  <tr>
    <th>Cause</th>
    <td><p>This error occurs if you created an uppercase table name and then
      activated lowercase table names.</p>

    <p>You activate lowercase table names either by:</p>

    <ul>

      <li>Setting the optional <code>enable_lower_case_table_names</code> parameter to <code>true</code>
      with the cf CLI. For more information about the parameter, see
      <a href='./change-default.html#lowercase'>Lowercase Table Names</a>.</li>

      <li>Selecting <strong>Enable Lower Case Table Names</strong> in
      the <strong>Mysql Configuration</strong> pane of the tile. For more
      information about this configuration,
      see <a href='./install-config.html#mysql'>Configure MySQL</a>.</li>
    </ul>
</td>
  </tr>

  <tr>
    <th style="vertical-align: top; padding-top: 1em;">Solution</th>
    <td><p>To resolve this issue:</p>
    <ol>
      <li>Deactivate lowercase table names by doing one of the following:
          <ul>
            <li>Set the optional <code>enable_lower_case_table_names</code> parameter to <code>false</code>
            with the cf CLI.
            For instructions, see <a href='./change-default.html#parameters'>Set Optional Parameters</a>.</li>
            <li>Activate lowercase table names in the tile:
              <ol>
              <li>Deselect <strong>Enable Lower Case Table Names</strong> in
            the <strong>Mysql Configuration</strong> pane of the tile.</li>
              <li> Navigate to the <%= vars.ops_manager %> Installation Dashboard,
        click <strong>Review Pending Changes</strong>, and then click
        <strong>Apply Changes</strong>.</li>
            </ol></li>
        </ul>
      </li>

      <li>
        (Optional) If you want to activate  lowercase table names again,
        rename your table to lowercase and then activate lowercase table names.
      </li>
      </ol>
      </td>
  </tr>

</table>
</div>


###<a id="ha"></a>Highly Available Cluster Errors

This section provides solutions for the following errands:

+ [Unresponsive Node in a Highly Available Cluster](#unresponsive)
+ [Many Replication Errors in Logs for Highly Available Clusters](#replication-errors)

<a name="unresponsive"></a>

<div>

  <table class="nice">
    <style>
      main table {
        table-layout: fixed;
      }
    </style>
  <col width="20%">
  <col width="80%">
  <tr>
  <th colspan="2" style="text-align: left;"> <br>
    Unresponsive Node in a Highly Available Cluster
  <br><br></th>
  </tr>

  <tr>
    <th>Symptom</th>
    <td>
    A client connected to a <%= vars.product_short %> cluster node reports the following error:

    <pre class="terminal">WSREP has not yet prepared this node for application use</pre>
    Some clients might instead return the following:
    <pre class="terminal">
      unknown error
    </pre>
    </td>
  </tr>

  <tr>
    <th>Cause</th>
    <td>If the client is connected to a <%= vars.product_short %> cluster node and that node loses connection to the rest of the cluster, the node stops accepting writes. If the connection to this node is made through the proxy, the proxy automatically
    re-routes further connections to a different node.</td>
  </tr>

  <tr>
    <th style="vertical-align: top; padding-top: 1em;">Solution</th>
    <td>A node can become unresponsive for a number of reasons. For solutions, see the following:

<ul>
  <li>
    <strong>Network Latency</strong>: If network latency causes a node to become unresponsive, the node drops but eventually rejoins. The node automatically rejoins only if one node has left the cluster. Consult your IaaS network settings to reduce your network latency. <hr></li>
  <li>
    <strong>MySQL Process Failure:</strong> If the MySQL process crashes, <code>monit</code>
    and BOSH restores the process. If the process is not restored, run the
    <code>download-logs</code> tool and consult the error logs it generates. For more information, see the
    <a href="#download-logs">download-logs</a> section.<hr>
  </li>
  <li>
    <strong>Firewall Rule Change:</strong>
    If your firewall rules change, it might prevent a node from communicating with the rest of the cluster. This causes the node to become unresponsive. In this case, the logs show the node leaving the cluster but do not show network latency errors.
    <br><br>
    To confirm that the node is unresponsive because of a firewall rule change, SSH from a responsive node to the unresponsive node. If you cannot connect, the node is unresponsive due to a firewall rule change. Change your firewall rules to activate the
    unresponsive node to rejoin the cluster.<hr>
  </li>
  <li>
    <strong>VM Failure:</strong>
    If you cannot SSH into a node and you are not detecting either network latency or firewall issues, your node might be down due to VM failure. To confirm that the node is unresponsive and recreate the VM, see
    <a href="#recreate-VM">
      Recreate a Corrupted VM in a Highly Available</a>.<hr>
  </li>
  <li>
    <strong>Node Unable to Rejoin:</strong> If a detached existing node fails to join the cluster, its
    <code>sequence_number</code> might be higher than those of the nodes with quorum. A higher
    <code>sequence_number</code> on the detached node indicates that it has recent changes to the
     data that the primary component lacks. You can verify this by looking at the node&rsquo;s error log at
    <code>/var/vcap/sys/log/pxc-mysql/mysql.err.log</code>.
    <br><br>
    To restore the cluster, complete one of the following:
    <ul>
      <li>
        <strong>Network Latency</strong>: If network latency causes a node to become unresponsive, the node drops but eventually rejoins. The node automatically rejoins only if one node has left the cluster. Consult your IaaS network settings to reduce your network latency. <hr></li>
      <li>
        <strong>MySQL Process Failure:</strong> If the MySQL process crashes, <code>monit</code>
        and BOSH restores the process. If the process is not restored, run the
        <code>download-logs</code> tool and consult the error logs it generates. For more information, see the
        <a href="#download-logs">download-logs</a> section below.<hr>
      </li>
      <li>
        If bootstrapping does not restore the cluster, you can manually force
        the node to rejoin the cluster. This removes all of the unsynchronized data
        from the detached server node and creates a new copy of the cluster data on the node. For more
        information, see <a href="#manual-force">Force a Node to Rejoin a Highly Available Cluster Manually</a>.
        <p class="note warning">
          <strong>Warning</strong>: Forcing a node to rejoin the cluster is a destructive procedure. Only do this procedure with the assistance of
          <a href="https://support.pivotal.io">Support</a>.
        </p>
      </li>
    </ul>
</td>
  </tr>

</table>
</div>

<a name="replication-errors"></a>

<div>

  <table class="nice">
    <style>
      main table {
        table-layout: fixed;
      }
    </style>
  <col width="20%">
  <col width="80%">
  <tr>
  <th colspan="2" style="text-align: left;"> <br>
    Many Replication Errors in Logs for Highly Available Clusters
  <br><br></th>
  </tr>

  <tr>
    <th>Symptom</th>
    <td>
    You see many replication errors in the MySQL logs, like the following:

    <pre class="terminal">
    160318 9:25:16 [Warning] WSREP: RBR event 1 Query apply warning: 1, 16992456
    160318 9:25:16 [Warning] WSREP: Ignoring error for TO isolated action: source: abcd1234-abcd-1234-abcd-1234abcd1234 version: 3 local: 0 state: APPLYING flags: 65 conn_id: 246804 trx_id: -1 seqnos (l: 865022, g: 16992456, s: 16992455, d: 16992455, ts: 2530660989030983)
    160318 9:25:16 [ERROR] Slave SQL: Error 'Duplicate column name 'number'' on query. Default database: 'cf_0123456_1234_abcd_1234_abcd1234abcd'. Query: 'ALTER TABLE ...'
    </pre>
    </td>
  </tr>

  <tr>
    <th>Cause</th>
    <td>This problem happens when there are errors in SQL statements.</td>
  </tr>

  <tr>
    <th style="vertical-align: top; padding-top: 1em;">Solution</th>
    <td>
    For solutions for replication errors in MySQL log files, see the following table:

      <table class="nice">
        <tr>
          <th>Additional Error</th>
          <th>Solution</th>
        </tr>
        <tr>
          <td>
            <code>ALTER TABLE</code>
            errors</td>
          <td>Fix the
            <code>ALTER TABLE</code>
            error.<br>
            This error can occur when an app issues an invalid data definition statement. Other nodes log this problem as a replication error because they fail to replicate the
            <code>ALTER TABLE</code>.</td>
        </tr>
        <tr>
          <td>Increased persistent disk usage or running out of working memory</td>
          <td>Decode the
            <code>GRA_*.log</code>
            files and look for errors. See
            <a href="https://community.pivotal.io/s/article/How-to-decode-Galera-GRA-logs-for-MySQL-for-PCF-v1-10">
              How to decode Galera GRA log files</a>
            in the Support knowledge base. The GRA log files contain failing DDL statements.</td>
        </tr>
      </table>

      If you see replication errors, but no <code>ALTER TABLE</code>
      or persistent disk or memory issues, you can ignore the replication errors.
    </td>
  </tr>

</table>
</div>

###  <a id="failed-adbr-backups"></a>Failed Backups

<p>If an automated backup or a backup initiated from the ApplicationDataBackupRestore (adbr) plug-in fails,
verify that the 2345 port from the TAS for VMs to the ODB component is open.</p>

<a name="unable-to-determine"></a>

<div>

  <table class="nice">
    <style>
      main table {
        table-layout: fixed;
      }
    </style>
  <col width="20%">
  <col width="80%">
  <tr>
  <th colspan="2" style="text-align: left;"> <br>
    Automated Backups or adbr Plug-in Backups Fail
  <br><br></th>
  </tr>

  <tr>
    <th>Symptom</th>
    <td>
    The following are true:<br><br>
    <ul>
      <li>The backup fails.</li>
      <li>The adbr-api logs for the broker show:
       <pre class="terminal">backup failed with response: 502 Bad Gateway: Registered endpoint failed to handle the request.</pre>
      </li>
      <li>The gorouter logs on the TAS for VMs deployment show:
       <pre class="terminal">adbr-api.SYSTEM-DOMAIN - [2021-01-20T19:30:00.911080271Z] "POST /service_instances/acb85c98-151e-4f13-9f0f-de057ef18d67/backup HTTP/1.1" 502 ... x_cf_routererror:"endpoint_failure" ...</pre>
       Where <code>SYSTEM-DOMAIN</code> is your system domain.
      </li>
    </ul>
    </td>
  </tr>

  <tr>
    <th>Cause</th>
    <td>
      Port 2345 that allows communication between the TAS for VMs and ODB components is closed.
      </td>
  </tr>

  <tr>
    <th style="vertical-align: top; padding-top: 1em;">Solution</th>
    <td>
    Open port 2345 from the TAS for VMs component to the ODB component.
    See <a href="about.html#mysql-ports">Required Networking Rules for Tanzu SQL for VMs</a>
    in <em>On-Demand Networking</em>.
      </td>
  </tr>

</table>
</div>

##  <a id="components"></a>  Troubleshoot Components

This section provides guidance on checking for and fixing issues in on-demand service components.

### <a id="bosh"></a> BOSH Problems

#### <a id="large-queue"></a> Large BOSH Queue


<%= partial '/services-tshoot/tshoot-comp-large-queue' %>

<p>
  On-demand service brokers add tasks to the BOSH request queue, which can back up
  and cause delay under heavy loads.
  An app developer who requests a new Tanzu SQL for VMs instance sees
  <code>create in progress</code> in the Cloud Foundry Command Line Interface (cf CLI) until
  BOSH processes the queued request.
</p>

<p>
  Ops Manager currently deploys two BOSH workers to process its' queue.
  Users of future versions of Ops Manager can configure the number of BOSH workers.
</p>

<h3 id="-configuration"><a id="bosh-config"></a> Configuration</h3>

<h4 id="-service-instances-in-failing-state"><a id="bosh-instance-fail"></a> Service Instances in Failing State</h4>


### <a id="bosh-config"></a> Configuration

#### <a id="bosh-instance-fail"></a> Service Instances in Failing State

<%= partial '/services-tshoot/tshoot-comp-bosh-instance-fail' %>


###  <a id="auth"></a>  Authentication

#### <a id="uaa-change"></a> UAA Changes

<%= partial '/services-tshoot/tshoot-comp-uaa-change' %>
<p>
    If you have rotated any UAA user credentials then you might see authentication
    issues in the service broker logs.
</p>

<p>
    To resolve this, redeploy the Tanzu SQL for VMs tile in Ops Manager.
    This provides the broker with the latest configuration.
</p>

<p class="note">
    <strong>Note</strong>: You must ensure that any changes to UAA
    credentials are reflected in the Ops Manager <code>credentials</code>
    tab of the VMware Tanzu Application Service for VMs tile.
</p>

<h3 id="-networking"><a id="network"></a>  Networking</h3>

<p>
    Common issues with networking include:
</p>

<table class="nice">
    <col width="50%">
    <col width="50%">
    <th>Issue</th>
    <th>Solution</th>
    <tr>
        <td>Latency when connecting to the Tanzu SQL for VMs service instance to create or delete a binding.</td>
        <td>Try again or improve network performance.</td>
    </tr>
    <tr>
        <td>Firewall rules are blocking connections from the Tanzu SQL for VMs service broker to the service instance.</td>
        <td>Open the Tanzu SQL for VMs tile in Ops Manager and check the two networks configured in the <strong>Networks</strong> pane. Ensure that these networks allow access to each other.</td>
    </tr>
    <tr>
        <td>Firewall rules are blocking connections from the service network to the BOSH director network.</td>
        <td>Ensure that service instances can access the Director so that the BOSH agents can report in.</td>
    </tr>
    <tr>
        <td>Apps cannot access the service network.</td>
        <td>Configure Cloud Foundry application security groups to allow runtime access to the service network.</td>
    </tr>
    <tr>
        <td>Problems accessing BOSH’s UAA or the BOSH director.</td>
        <td>Follow network troubleshooting and check that the BOSH director is online</td>
    </tr>
</table>

#### Validate Service Broker Connectivity to Service Instances

To validate connectivity, do the following:

1.  View the BOSH deployment name for your service broker by running:

    ```
    bosh deployments
    ```

2.  SSH into the Tanzu SQL for VMs service broker by running:

    ```
    bosh -d DEPLOYMENT-NAME ssh
    ```

3.  If no BOSH `task-id` appears in the error message, look in the broker log using the `broker-request-id` from the task.


###  <a id="network"></a>  Networking


<%= partial '/services-tshoot/tshoot-comp-network' %>


####  <a id="broker-to-instances"></a>  Validate Service Broker Connectivity to Service Instances
To determine whether there is an issue with the Tanzu SQL for VMs deployment:

1.  Inspect the VMs by running:

    ```
    bosh -d service-instance_GUID vms --vitals
    ```

2.  For additional information, run:

    ```
    bosh -d service-instance_GUID instances --ps --vitals
    ```

If the VM is failing, follow the service-specific information. Any unadvised corrective actions (such as running BOSH `restart` on a VM) can cause issues in the service instance.

A failing process or failing VM might come back automatically after a temporary service outage. See [VM Process Failure](./interruptions.html#process-fail) and [VM Failure](./interruptions.html#vm-fail).


<%= partial '/services-tshoot/tshoot-comp-broker-to-instances' %>


####  <a id="app-to-instances"></a>  Validate App Access to Service Instance


<%= partial '/services-tshoot/tshoot-comp-app-to-instances' %>


###  <a id="quotas"></a>  Quotas

#### <a id="plan-quotas"></a> Plan Quota Issues

<%= partial '/services-tshoot/tshoot-comp-plan-quotas' %>


####  <a id="global-quotas"></a>  Global Quota Issues

<%= partial '/services-tshoot/tshoot-comp-global-quotas' %>


###  <a id="failing-jobs"></a>  Failing Jobs and Unhealthy Instances

<%= partial '/services-tshoot/tshoot-comp-failing-jobs' %>

A failing process or failing VM might come back automatically after a temporary service outage. See
<a href="./interruptions.html#process-fail">VM Process Failure</a>
and <a href="./interruptions.html#vm-fail">VM Failure</a>.

###  <a id="az-region-fail"></a>  AZ or Region Failure

Failures at the IaaS level, such as Availability Zone (AZ) or region failures,
can interrupt service and require manual restoration.
See <a href="./interruptions.html#az-fail">AZ Failure</a> and <a href="./interruptions.html#region-fail">Region Failure</a>.

##  <a id="techniques"></a>  Techniques for Troubleshooting

Instructions on interacting with the on-demand service broker and on-demand service
instance BOSH deployments, and on performing general maintenance and housekeeping tasks

### <a id="parse-error"></a> Parse a Cloud Foundry (CF) Error Message

<%= partial '/services-tshoot/tshoot-tech-parse-error' %>


###  <a id="bosh-cf-access"></a>  Access Broker and Instance Logs and VMs


<%= partial '/services-tshoot/tshoot-tech-bosh-cf-access' %>


####  <a id="access-broker"></a>  Access Broker Logs and VMs

<%= partial '/services-tshoot/tshoot-tech-access-broker' %>


####  <a id="access-instance"></a>  Access Service Instance Logs and VMs


<%= partial '/services-tshoot/tshoot-tech-access-instance' %>

### <a id="broker-errands"></a> Run Service Broker Errands to Manage Brokers and Instances

<%= partial '/services-tshoot/tshoot-tech-broker-errands' %>

#### <a id="register-broker"></a> Register Broker

<%= partial '/services-tshoot/tshoot-tech-register-broker' %>

#### <a id="deregister-broker"></a> Deregister Broker

<%= partial '/services-tshoot/tshoot-tech-deregister-broker' %>

#### <a id="upgrade-all"></a> Upgrade All Service Instances

<%= partial '/services-tshoot/tshoot-tech-upgrade-all' %>

#### <a id="delete-all"></a> Delete All Service Instances

<%= partial '/services-tshoot/tshoot-tech-delete-all' %>

### <a id="detect-orphans"></a> Detect Orphaned Service Instances

<%= partial '/services-tshoot/tshoot-tech-detect-orphans' %>

###  <a id="view-resources"></a>  View Resource Saturation and Scaling

<%= partial '/services-tshoot/tshoot-tech-view-resources' %>


###  <a id="id-instance-owner"></a> Identify Apps using a Service Instance

<%= partial '/services-tshoot/tshoot-tech-id-instance-owner' %>


###  <a id="monitor-quota"></a>  Monitor Quota Saturation and Service Instance Count

<%= partial '/services-tshoot/tshoot-tech-monitor-quota' %>


###  <a id="trouble-ha"></a>Techniques for Troubleshooting Highly Available Clusters

If your cluster is experiencing downtime or in a degraded state, VMware recommends
gathering information to diagnose the type of failure the cluster is experiencing with  the following workflow:
See <a href="./interruptions.html#az-fail">AZ Failure</a> and <a href="./interruptions.html#region-fail">Region Failure</a>.</p>

<h2 id="-techniques-for-troubleshooting"><a id="techniques"></a>  Techniques for Troubleshooting</h2>

<p>Instructions on interacting with the on-demand service broker and on-demand service
instance BOSH deployments, and on performing general maintenance and housekeeping tasks</p>

<h3 id="-parse-a-cloud-foundry-(cf)-error-message"><a id="parse-error"></a> Parse a Cloud Foundry (CF) Error Message</h3>



<p>
  Failed operations (create, update, bind, unbind, delete) result in an error message.
  You can retrieve the error message later by running the cf CLI command <code>cf service INSTANCE-NAME</code>.
</p>

```
$ cf service myservice

Service instance: myservice
Service: super-db
Bound apps:
Tags:
Plan: dedicated-vm
Description: Dedicated Instance
Documentation url:
Dashboard:

Last Operation
Status: create failed
Message: Instance provisioning failed: There was a problem completing your request.
     Please contact your operations team providing the following information:
     service: redis-acceptance,
     service-instance-guid: ae9e232c-0bd5-4684-af27-1b08b0c70089,
     broker-request-id: 63da3a35-24aa-4183-aec6-db8294506bac,
     task-id: 442,
     operation: create
Started: 2017-03-13T10:16:55Z
Updated: 2017-03-13T10:17:58Z
```

<p>
  Use the information in the <code>Message</code> field to debug further.
  Provide this information to Support when filing a ticket.
</p>

<p>
  The <code>task-id</code> field maps to the BOSH task ID.
  For more information on a failed BOSH task, use the <code>bosh task TASK-ID</code>.
</p>

<p>
  The <code>broker-request-guid</code> maps to the portion of the On-Demand Broker log
  containing the failed step.
  Access the broker log through your syslog aggregator, or access BOSH logs for
  the broker by typing <code>bosh logs broker 0</code>.
  If you have more than one broker instance, repeat this process for each instance.
</p>

<h3 id="-access-broker-and-instance-logs-and-vms"><a id="bosh-cf-access"></a>  Access Broker and Instance Logs and VMs</h3>


<p>
  Before following these procedures, log in to the
  <a href="https://docs.pivotal.io/pivotalcf/cf-cli/getting-started.html">cf CLI</a> and the
  <a href="https://docs.pivotal.io/pivotalcf/customizing/trouble-advanced.html#prepare">BOSH CLI</a>.
</p>

<h4 id="-access-broker-logs-and-vms"><a id="access-broker"></a>  Access Broker Logs and VMs</h4>



<p>
    You can <a href="https://docs.pivotal.io/pivotalcf/customizing/troubleshooting.html#component_logs">access logs using Ops Manager</a>
    by clicking on the <strong>Logs</strong> tab in the tile and downloading the broker logs.
</p>

<p>
    To access logs using the BOSH CLI, do the following:
</p>

<ol>
    <li>
        <p>
            Identify the on-demand broker (ODB) deployment by running the following command:
        </p>
        <code>bosh deployments</code>
    </li>
    <li>
        <p>
            View VMs in the deployment by running the following command:
        </p>
        <code>bosh -d DEPLOYMENT-NAME instances</code>
    </li>
    <li>
        <p>
            SSH onto the VM by running the following command:
        </p>
        <code>bosh -d DEPLOYMENT-NAME ssh</code>
    </li>
    <li>
        <p>
            Download the broker logs by running the following command:
        </p>
        <code>bosh -d DEPLOYMENT-NAME logs</code>
    </li>
</ol>

<p>
    The archive generated by BOSH includes the following logs:
</p>

<table class="nice">
    <th>Log Name</th>
    <th>Description</th>
    <tr>
        <td>broker.stdout.log</td>
        <td>Requests to the on-demand broker and the actions the broker performs
            while orchestrating the request (e.g. generating a manifest and calling BOSH).
            Start here when troubleshooting.</td>
    </tr>
    <tr>
        <td>bpm.log</td>
        <td>Control script logs for starting and stopping the on-demand broker.</td>
    </tr>
    <tr>
        <td>post-start.stderr.log</td>
        <td>Errors that occur during post-start verification.</td>
    </tr>
    <tr>
        <td>post-start.stdout.log</td>
        <td>Post-start verification.</td>
    </tr>
    <tr>
        <td>drain.stderr.log</td>
        <td>Errors that occur while running the drain script.</td>
    </tr>
</table>

<h4 id="-access-service-instance-logs-and-vms"><a id="access-instance"></a>  Access Service Instance Logs and VMs</h4>



<ol>
    <li>
        <p>
            To target an individual service instance deployment, retrieve the GUID of your
            service instance with the following cf CLI command:
        </p>
        <code>cf service MY-SERVICE --guid</code>
    </li>
    <li>
        <p>
            To view VMs in the deployment, run the following command:
        </p>
        <code>bosh -d service-instance_GUID instances</code>
    </li>
    <li>
        <p>
            To SSH into a VM, run the following command:
        </p>
        <code>bosh -d service-instance_GUID ssh</code>
    </li>
    <li>
        <p>
            To download the instance logs, run the following command:
        </p>
        <code>bosh -d service-instance_GUID logs</code>
    </li>
</ol>

<h3 id="-run-service-broker-errands-to-manage-brokers-and-instances"><a id="broker-errands"></a> Run Service Broker Errands to Manage Brokers and Instances</h3>


<p>
  From the BOSH CLI, you can run service broker errands that manage the service
  brokers and perform mass operations on the service instances that the brokers created.
  These service broker errands include:
</p>

<ul>
  <li>
    <p>
      <a href="#register-broker"><code>register-broker</code></a> registers a broker with the Cloud Controller
      and lists it in the Marketplace.
    </p>
  </li>
  <li>
    <p>
      <a href="#deregister-broker"><code>deregister-broker</code></a> deregisters a broker with the Cloud
      Controller and removes it from the Marketplace.
    </p>
  </li>
  <li>
    <p>
      <a href="#upgrade-all"><code>upgrade-all-service-instances</code></a> upgrades existing instances of
      a service to its latest installed version.
    </p>
  </li>
  <li>
    <p>
      <a href="#delete-all"><code>delete-all-service-instances</code></a> deletes all instances of service.
    </p>
  </li>
  <li>
    <p>
      <a href="#detect-orphans"><code>orphan-deployments</code></a> detects &ldquo;orphan&rdquo; instances that are
      running on BOSH but not registered with the Cloud Controller.
    </p>
  </li>
</ul>

<p>
  To run an errand, run the following command:
</p>

<code>bosh -d DEPLOYMENT-NAME run-errand ERRAND-NAME</code>

<p>
  For example:
</p>

<pre class="terminal">bosh -d my-deployment run-errand deregister-broker</pre>

<h4 id="-register-broker"><a id="register-broker"></a> Register Broker</h4>


<p>
  The <code>register-broker</code> errand does the following:
</p>

<ul>
  <li>Registers the service broker with Cloud Controller.</li>
  <li>
    Activates service access for any plans that are activated on the tile.
  </li>
  <li>Deactivates service access for any plans that are deactivated on the tile.
  </li>
  <li>Does nothing for any plans that are set to manual on the tile.</li>
</ul>

<p>
  You can run this errand whenever the broker is re-deployed with new catalog metadata to
  update the Marketplace.
</p>

<p>
  Plans with deactivated service access are only visible to admin Cloud Foundry
  users. Non-admin Cloud Foundry users, including Org Managers and Space Managers, cannot
  see these plans.
</p>

<h4 id="-deregister-broker"><a id="deregister-broker"></a> Deregister Broker</h4>


<p>
  This errand deregisters a broker from Cloud Foundry.
</p>

<p>
  The errand does the following:
</p>

<ul>
  <li>Deletes the service broker from Cloud Controller</li>
  <li>Fails if there are any service instances, with or without bindings</li>
</ul>

<p>Use the <a href="#delete-all">
  Delete All Service Instances errand</a> to delete any existing service instances.
</p>

<p>
  To run the errand, run the following command:
</p>

<code>bosh -d DEPLOYMENT-NAME run-errand deregister-broker</code>

<h4 id="-upgrade-all-service-instances"><a id="upgrade-all"></a> Upgrade All Service Instances</h4>


<p>
    The <code>upgrade-all-service-instances</code> errand does the following:
</p>

<ul>
    <li>Collects all of the service instances that the on-demand broker has registered.</li>
    <li>Issues an upgrade command and deploys the a new manifest to the on-demand broker for each
        service instance.</li>
    <li>Adds to a retry list any instances that have ongoing BOSH tasks at the time of upgrade.</li>
    <li>Retries any instances in the retry list until all instances are upgraded.</li>
</ul>

<p>
    When you make changes to the plan configuration, the errand
    upgrades all the Tanzu SQL for VMs service instances to the latest version of the plan.
</p>

<p>
    If any instance fails to upgrade, the errand fails immediately.
    This prevents systemic problems from spreading to the rest of your service instances.
</p>

<h4 id="-delete-all-service-instances"><a id="delete-all"></a> Delete All Service Instances</h4>


<p>
  This errand uses the Cloud Controller API to delete all instances of your broker’s
  service offering in every Cloud Foundry org and space. It only deletes instances
  the Cloud Controller knows about.
  It does not delete orphan BOSH deployments.
</p>

<p class="note">
  <strong>Note</strong>: Orphan BOSH deployments do not correspond to a known service instance.
  While rare, orphan deployments can occur. Use the <code>orphan-deployments</code>
  errand to identify them.
</p>

<p>
  The <code>delete-all-service-instances</code> errand does the following:
</p>

<ol>
  <li>Unbinds all apps from the service instances.</li>
  <li>
    Deletes all service instances sequentially. Each service instance deletion includes:
    <ol>
      <li>Running any pre-delete errands</li>
      <li>Deleting the BOSH deployment of the service instance</li>
      <li>Removing any ODB-managed secrets from BOSH CredHub</li>
      <li>Checking for instance deletion failure, which results in the errand failing immediately</li>
    </ol>
  </li>
  <li>
    Determines whether any instances have been created while the errand was running.
    If new instances are detected, the errand returns an error.
    In this case, VMware recommends running the errand again.
  </li>
</ol>

<p class="note warning">
  <strong>Warning:</strong> Use extreme caution when running this errand.
  You can only use it when you want to totally destroy all of the on-demand service
  instances in an environment.
</p>

<p>
  To run the errand, run the following command:
</p>

<code>bosh -d service-instance_GUID delete-deployment</code>

<h3 id="-detect-orphaned-service-instances"><a id="detect-orphans"></a> Detect Orphaned Service Instances</h3>


<p>
  A service instance is defined as &ldquo;orphaned&rdquo; when the BOSH deployment for the
  instance is still running, but the service is no longer registered in Cloud Foundry.
</p>

<p>
  The <code>orphan-deployments</code> errand collates a list of service deployments that have
  no matching service instances in Cloud Foundry and return the list to the operator.
  It is then up to the operator to remove the orphaned BOSH deployments.
</p>

<p>
  To run the errand, run the following command:
</p>

<code>bosh -d DEPLOYMENT-NAME run-errand orphan-deployments</code>

<p>
  <strong>If orphan deployments exist</strong>&mdash;The errand script does the following:
</p>

<ul>
  <li>Exit with exit code 10</li>
  <li>Output a list of deployment names under a <code>[stdout]</code> header</li>
  <li>Provide a detailed error message under a <code>[stderr]</code> header</li>
</ul>

<p>
  For example:
</p>

<pre class="terminal">
[stdout]
[{"deployment\_name":"service-instance\_80e3c5a7-80be-49f0-8512-44840f3c4d1b"}]

[stderr]
Orphan BOSH deployments detected with no corresponding service instance in Cloud Foundry. Before deleting any deployment it is recommended to verify the service instance no longer exists in Cloud Foundry and any data is safe to delete.

Errand 'orphan-deployments' completed with error (exit code 10)
</pre>

<p>
  These details are also available through the BOSH <code>/tasks/</code> API endpoint for use in scripting:
</p>

<pre class="terminal">
$ curl 'https<span>:</span>//bosh-user:bosh-password@bosh-url:25555/tasks/task-id/output?type=result' | jq .
{
  "exit_code": 10,
  "stdout": "[{"deployment_name":"service-instance_80e3c5a7-80be-49f0-8512-44840f3c4d1b"}]\n",
  "stderr": "Orphan BOSH deployments detected with no corresponding service instance in Cloud Foundry. Before deleting any deployment it is recommended to verify the service instance no longer exists in Cloud Foundry and any data is safe to delete.\n",
  "logs": {
    "blobstore_id": "d830c4bf-8086-4bc2-8c1d-54d3a3c6d88d"
  }
}
</pre>

<p>
  <strong>If no orphan deployments exist</strong>&mdash;The errand script does the following:
</p>

<ul>
  <li>Exit with exit code 0</li>
  <li>Stdout is an empty list of deployments</li>
  <li>Stderr is <code>None</code></li>
</ul>

<pre class="terminal">
[stdout]
[]

[stderr]
None

Errand 'orphan-deployments' completed successfully (exit code 0)
</pre>

<p>
  <strong>If the errand encounters an error during running</strong>&mdash;The errand script does the following:
</p>

<ul>
  <li>Exit with exit 1</li>
  <li>Stdout is empty</li>
  <li>Any error messages are under stderr</li>
</ul>

<p>
  To clean up orphaned instances, run the following command on each instance:
</p>

<p class="note warning">
  <strong>WARNING: </strong> Running this command might leave IaaS resources in an unusable state.
</p>

<code>bosh delete-deployment service-instance_SERVICE-INSTANCE-GUID</code>

<h3 id="-reinstall-a-tile"><a id="reinstall"></a>  Reinstall a Tile</h3>

<p>To reinstall the Tanzu SQL for VMs tile, see <a href="https://community.pivotal.io/s/article/Reinstalling-MySQL-for-Pivotal-Cloud-Foundry-version-2-and-above">Reinstalling MySQL for Pivotal Cloud Foundry version 2 and higher</a>
in the Support Knowledge Base.</p>

<h3 id="-view-resource-saturation-and-scaling"><a id="view-resources"></a>  View Resource Saturation and Scaling</h3>


<p>
    To view usage statistics for any service, do the following:
</p>

<ol>
    <li>
        <p>
            Run the following command:
        </p>
        <code>bosh -d DEPLOYMENT-NAME vms --vitals</code>
    </li>
    <li>
        <p>
            To view process-level information, run:
        </p>
        <code>bosh -d DEPLOYMENT-NAME instances --ps</code>
    </li>
</ol>

<h3 id="-identify-apps-using-a-service-instance"><a id="id-instance-owner"></a> Identify Apps using a Service Instance</h3>


<p>
  To identify which apps are using a specific service instance from the
  name of the BOSH deployment:
</p>

<ol>
  <li>Take the deployment name and strip the <code>service-instance_</code> leaving you with the GUID.</li>
  <li>Log in to CF as an admin.</li>
  <li>
    Obtain a list of all service bindings by running the following:
    <code>cf curl /v2/service_instances/GUID/service_bindings</code>
  </li>
  <li>
    The output from the curl gives you a list of <code>resources</code>,
    with each item referencing a service binding, which contains the <code>APP-URL</code>.
    To find the name, org, and space for the app, run the following:
    <ol>
      <li><code>cf curl APP-URL</code> and record the app name under <code>entity.name</code>.</li>
      <li><code>cf curl SPACE-URL</code> to obtain the space, using the <code>entity.space_url</code>
        from the curl.
        Record the space name under <code>entity.name</code>.
      </li>
      <li>
        <code>cf curl ORGANIZATION-URL</code> to obtain the org, using the
        <code>entity.organization_url</code> from the curl.
        Record the organization name under <code>entity.name</code>.
      </li>
    </ol>
  </li>
</ol>

<p class="note">
  <strong>Note:</strong> When running <code>cf curl</code> ensure that you query
  all pages, because the responses are limited to a certain number of bindings per page.
    The default is 50.
    To find the next page curl the value under <code>next_url</code>.
</p>

<h3 id="-monitor-quota-saturation-and-service-instance-count"><a id="monitor-quota"></a>  Monitor Quota Saturation and Service Instance Count</h3>

<p>
  Quota saturation and total number of service instances are available through ODB
  metrics emitted to Loggregator. The metric names are shown in the following table::
</p>

<table>
  <thead>
    <tr>
      <th><strong>Metric Name</strong></th>
      <th><strong>Description</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>on-demand-broker/SERVICE-NAME-MARKETPLACE/quota_remaining</code></td>
      <td>global quota remaining for all instances across all plans</td>
    </tr>
    <tr>
      <td><code>on-demand-broker/SERVICE-NAME-MARKETPLACE/PLAN-NAME/quota_remaining</code></td>
      <td>quota remaining for a particular plan</td>
    </tr>
    <tr>
      <td><code>on-demand-broker/SERVICE-NAME-MARKETPLACE/total_instances</code></td>
      <td>total instances created across all plans</td>
    </tr>
    <tr>
      <td><code>on-demand-broker/SERVICE-NAME-MARKETPLACE/PLAN-NAME/total_instances</code></td>
      <td>total instances created for a given plan</td>
    </tr>
  </tbody>
</table>

<p class="note">
  <strong>Note</strong>: Quota metrics are not emitted if no quota has been set.
</p>

<h3 id="techniques-for-troubleshooting-highly-available-clusters"><a id="trouble-ha"></a>Techniques for Troubleshooting Highly Available Clusters</h3>

<p>If your cluster is experiencing downtime or in a degraded state, VMware recommends
gathering information to diagnose the type of failure the cluster is experiencing with  the following workflow:</p>

<ol>
  <li>Consult solutions for common errors. See
    <a href="#ha">Highly Available Cluster Troubleshooting Errors</a>.
  </li>
  <li>Use
    <code>mysql-diag</code>
    to view a summary of the network, disk, and replication state of each cluster node. Depending on the output from
    <code>mysql-diag</code>, you might recover your cluster with the following troubleshooting techniques:
    <ul>
      <li>To force a node to rejoin the cluster, see
        <a href="#manual-force">Force a Node to Rejoin a Highly Available Cluster Manually</a>.</li>
      <li>To re-create a corrupted VM, see
        <a href="#recreate-VM">Re-create a Corrupted VM in a Highly Available Cluster</a>.</li>
      <li>To check if replication is working, see
        <a href="#check-replication">Check Replication in a Highly Available Cluster</a>.</li>
    </ul>
    For more information about
    <code>mysql-diag</code>, see
    <a href="./mysql-diag.html">Running mysql-diag</a>.
  </li>

  <li>
    Run <code>download-logs</code> against each node in your <%= vars.product_short %> cluster, proxies, and jumpbox VM.
    You must run
    <code>download-logs</code> before attempting recovery because any failures in the recovery procedure can result in logs being lost or made inaccessible.
    <br>
    For more information, see the <a href="#download-logs">download-logs</a>
    section.
    <br>
    <p class="note">
      <strong>Note:</strong>
      VMware recommends that you use the <code>-X</code> flag to get the complete
      set of available logs. However, if your cluster processes a high volume of
      transactions, the complete set might be too large and you can omit this flag
      to fetch the essential set of logs.
    </p>
  </li>

  <li>
    If you are uncertain about the recovery steps to take, submit a ticket through
    <a href="https://tanzu.vmware.com/support">Support</a>. When you submit a ticket provide the following information:
    <ul>
      <li>
        <strong>mysql-diag output:</strong>
        A summary of the network, disk, and replication state. The
        <a href="./mysql-diag.html">Running mysql-diag</a>
        topic explains how to run
        <strong>mysql-diag</strong>.
      </li>
      <li>
        <strong>download-logs logs:</strong>
        Logs from your <%= vars.product_short %> cluster, proxies, and jumpbox VM. The
        <a href="#download-logs" ">download-logs</a>
        section explains how to run
        <strong>download-logs</strong>.
      </li>
      <li>
        <strong>Deployment environment:</strong>
        The environment that <%= vars.product_short %> is running in such as <%= vars.app_runtime_full %> or a service tile.</li>
      <li>
        <strong>Version numbers:</strong>
        The versions of the installed <%= vars.ops_manager %>, <%= vars.app_runtime_abbr %>, and <%= vars.product_short %>.
      </li>
    </ul>
  </li>
</ol>

<p class="note warning">
  <strong>Warning:</strong>
  Do not attempt to resolve cluster issues by reconfiguring the cluster, such as changing the number of nodes or networks. Only follow the diagnosis steps in this document. If you are unsure how to proceed, contact
  <a href="https://tanzu.vmware.com/support">Support</a>.
</p>


### <a id="manual-force"></a> Force a Node to Rejoin a Highly Available Cluster Manually

If a detached node fails to rejoin the cluster after a configured grace period,
you can manually force the node to rejoin the cluster.
This procedure removes all the data on the node, forces the node to join the cluster,
and creates a new copy of the cluster data on the node.


<p class="note warning">
  <strong>Warning:</strong>
  If you manually force a node to rejoin the cluster, data stored on the local node is lost. Do not force nodes to rejoin the cluster if you want to preserve unsynchronized data. Only do this procedure with the assistance of
  <a href="https://tanzu.vmware.com/support">Support</a>.
</p>

Before following this procedure, try to bootstrap the cluster. For more information, see
<a href="./bootstrapping.html">Bootstrapping</a>.
<br><br>
To manually force a node to rejoin the cluster, do the following:

<ol>
  <li>
    SSH into the node by following the procedure in
    <a href="https://docs.vmware.com/en/VMware-Tanzu-Operations-Manager/2.10/vmware-tanzu-ops-manager/install-trouble-advanced.html#bosh-ssh-15">BOSH SSH</a>.
  </li>
  <li>
    Become root by running:
    <pre class="terminal"> sudo su</pre>
  </li>
  <li>
    Shut down the
    <code>mysqld</code>
    process on the node by running:
    <pre class="terminal">  monit stop galera-init </pre>
  </li>
  <li>
    Remove the unsynchronized data on the node by running:
    <pre class="terminal">  rm -rf /var/vcap/store/pxc-mysql</pre>
  </li>
  <li>
    Prepare the node before restarting by running:
    <pre class="terminal">  /var/vcap/jobs/pxc-mysql/bin/pre-start</pre>
  </li>
  <li>Restart the
    <code>mysqld</code>
    process by running:
    <pre class="terminal"> monit start galera-init</pre>
  </li>
</ol>


### <a id="recreate-VM"></a>Re-create a Corrupted VM in a Highly Available Cluster

To re-create a corrupted VM:

<ol>
  <li>To log in to the BOSH Director VM by doing the following procedures:
    <ol>
      <li>Gather the information needed to log in to the BOSH Director VM by doing the procedure in
        <a href="https://docs.vmware.com/en/VMware-Tanzu-Operations-Manager/2.10/vmware-tanzu-ops-manager/install-trouble-advanced.html#gather-credential-and-ip-address-information-1">Gather Credential and IP Address Information</a>&#46;</li>
      <li>Log in to the <%= vars.ops_manager %> VM by doing the procedure in
        <a href="https://docs.vmware.com/en/VMware-Tanzu-Operations-Manager/2.10/vmware-tanzu-ops-manager/install-trouble-advanced.html#log-in-to-the-ops-manager-vm-with-ssh-2">Log in to the <%= vars.ops_manager %> VM with SSH</a>&#46;</li>
      <li>Log in to the BOSH Director VM by doing the procedure in
        <a href="https://docs.vmware.com/en/VMware-Tanzu-Operations-Manager/2.10/vmware-tanzu-ops-manager/install-trouble-advanced.html#authenticate-with-the-bosh-director-vm-8">Authenticate with the BOSH Director VM</a>&#46;</li>
    </ol>
  </li>
  <li>
    Identify and re-create the unresponsive node with
    <code>bosh cloudcheck</code>, by doing the procedure in
    <a href="https://docs.vmware.com/en/VMware-Tanzu-Operations-Manager/2.10/vmware-tanzu-ops-manager/install-trouble-advanced.html#bosh-cloud-check-14">BOSH Cloudcheck</a>
    and run
    <code>Recreate VM using last known apply spec</code>.
    <p class="note warning">
      <strong>Warning:</strong>
      Recreating a node clears its' logs. Ensure the node is completely down before recreating it.
    </p>
    <p class="note warning">
      <strong>Warning:</strong>
      Only re-create one node. Do not re-create the entire cluster. If more than one node is down, contact
      <a href="https://tanzu.vmware.com/support">Support</a>.
    </p>
  </li>
</ol>


### <a id="check-replication"></a>Check Replication Status in a Highly Available Cluster

If you see stale data in your cluster, you can check whether replication is functioning normally.


To check the replication status, do the following:

1.  To log in to the BOSH Director VM, do the following:
    1.  Gather the information needed to log in to the BOSH Director VM by doing the procedure in [Gather Credential and IP Address Information](https://docs.pivotal.io/pivotalcf/customizing/trouble-advanced.html#gather).
    2.  Log in to the Ops Manager VM by doing the procedure in [Log in to the Ops Manager VM with SSH](https://docs.pivotal.io/pivotalcf/customizing/trouble-advanced.html#ssh).
2.  Create a dummy database in the first node by running:

    ```
    mysql -h FIRST-NODE-IP-ADDRESS \ -u YOUR-IDENTITY \ -p -e "create database verify_healthy;"
    ```

    Where:
    <ul>
      <li>
        <code>FIRST-NODE-IP-ADDRESS</code>
        is the IP address of the first node you recorded in step 1.
      </li>
      <li>
        <code>YOUR-IDENTITY</code> is the value of <code>identity</code>
        that you recorded in step 1.
      </li>
    </ul>
  </li>
  <li>
    Create a dummy table in the dummy database by running:
    <pre class="terminal">mysql -h FIRST-NODE-IP-ADDRESS \
      -u your-identity \
      -p -D verify_healthy \
      -e "create table dummy_table (id int not null primary key auto_increment, info text) \
      engine='innodb';"</pre>
  </li>
  <li>
    Insert data into the dummy table by running:
    <pre class="terminal">mysql -h FIRST-NODE-IP-ADDRESS \
      -u YOUR-IDENTITY \
      -p -D verify_healthy \
      -e "insert into dummy_table(info) values ('dummy data'),('more dummy data'),('even more dummy data');"</pre>
  </li>
  <li>
    <p>
      Query the table and verify that the three rows of dummy data exist on the first node by running:
    </p>
    <pre class="terminal">mysql -h FIRST-NODE-IP-ADDRESS \
      -u YOUR-IDENTITY \
      -p -D verify_healthy \
      -e "select * from dummy_table;"</pre>

    *   `FIRST-NODE-IP-ADDRESS` is the IP address of the first node you recorded in step 1.
    *   `YOUR-IDENTITY` is the value of `identity` that you recorded in step 1.

3.  Create a dummy table in the dummy database by running:

    ```
    mysql -h FIRST-NODE-IP-ADDRESS \ -u your-identity \ -p -D verify_healthy \ -e "create table dummy_table (id int not null primary key auto_increment, info text) \ engine='innodb';"
    ```

4.  Insert data into the dummy table by running:

    ```
    mysql -h FIRST-NODE-IP-ADDRESS \ -u YOUR-IDENTITY \ -p -D verify_healthy \ -e "insert into dummy_table(info) values ('dummy data'),('more dummy data'),('even more dummy data');"
    ```

5.  Query the table and verify that the three rows of dummy data exist on the first node by running:

    ```
    mysql -h FIRST-NODE-IP-ADDRESS \ -u YOUR-IDENTITY \ -p -D verify_healthy \ -e "select * from dummy_table;"
    ```

    When prompted for a password, provide the `password` value recorded in step 1.
    The previous command returns output similar to the following:

    <pre class="terminal">
  +----+----------------------+
  | id | info                 |
  +----+----------------------+
  |  4 | dummy data           |
  |  7 | more dummy data      |
  | 10 | even more dummy data |
  +----+----------------------+</pre>
  </li>
  <li>
    Verify that the other nodes contain the same dummy data
    by doing the following for each of the remaining MySQL server IP addresses:
    <ol>
      <li>Query the dummy table by running :
        <pre class="terminal">mysql -h NEXT-NODE-IP-ADDRESS \
          -u YOUR-IDENTITY \
          -p -D verify\_healthy \
          -e "select * from dummy_table;"</pre>

        When prompted for a password, provide the
        <code>password</code>
        value recorded in step 1.
      </li>
      <li>
        Verify that the node contains the same three rows of dummy data as the other nodes
        by running:

        <pre class="terminal">mysql -h NEXT-NODE-IP-ADDRESS \
          -u YOUR-IDENTITY \
          -p -D verify\_healthy \
          -e "select * from dummy\_table;"</pre>

        When prompted for a password, provide the
        <code>password</code>
        value recorded in step
        </li>

        <li>Verify that the above command returns output similar to the following:
        <pre class="terminal">
    +----+----------------------+
    | id | info                 |
    +----+----------------------+
    |  4 | dummy data           |
    |  7 | more dummy data      |
    | 10 | even more dummy data |
    +----+----------------------+ </pre>
      </li>
    </ol>
  </li>
  <li>
    <strong>If each MySQL server instance does not return the same result,</strong> before proceeding
    further or making any changes to your deployment, contact
    <a href="https://tanzu.vmware.com/support">Support</a>.
    <br>
    <strong>If each MySQL server instance returns the same result,</strong> then you can safely proceed
    to scaling down your cluster to a single node.
  </li>
    +----+----------------------+
    </pre>

6.  Verify that the other nodes contain the same dummy data by doing the following for each of the remaining MySQL server IP addresses:
    1.  Query the dummy table by running :
        ```
        mysql -h NEXT-NODE-IP-ADDRESS \ -u YOUR-IDENTITY \ -p -D verify\_healthy \ -e "select * from dummy_table;"
        ```
        When prompted for a password, provide the `password` value recorded in step 1.

    2.  Verify that the node contains the same three rows of dummy data as the other nodes by running:

        ```
        mysql -h NEXT-NODE-IP-ADDRESS \\
                  -u YOUR-IDENTITY \\
                  -p -D verify\\\_healthy \\
                  -e "select \* from dummy\\\_table;"
        ```
        When prompted for a password, provide the `password` value recorded in step 1.


    3.  Verify that the previous command returns output similar to the following:

            +----+----------------------+
            | id | info                 |
            +----+----------------------+
            |  4 | dummy data           |
            |  7 | more dummy data      |
            | 10 | even more dummy data |
            +----+----------------------+

7.  **If each MySQL server instance does not return the same result,** before proceeding further or making any changes to your deployment, contact [Support](https://support.pivotal.io/)
    **If each MySQL server instance returns the same result,** then you can safely proceed to scaling down your cluster to a single node.


<h2 id="-tools-for-troubleshooting"><a id="tools"></a>  Tools for Troubleshooting</h2>

<p>The troubleshooting techniques described here  use the following tools.</p>

<h3 id="download-logs"><a id="download-logs"></a>download-logs</h3>

<p><code>download-logs</code> is a script that you can run from your Ops Manager VM to aggregate
logs from your Tanzu SQL for VMs cluster nodes, proxies, and, with highly available clusters,
the jumpbox VM.</p>

<p>To use the <code>download-logs</code> script:</p>

<ol>
<li><p>Download and unzip the <code>download-logs</code> script from
<a href="https://network.pivotal.io/products/pivotal-mysql">VMware Tanzu Network</a>.</p></li>
<li><p>From the Ops Manager Installation Dashboard, navigate to <strong>BOSH Director</strong> &gt; <strong>Credentials</strong>.</p></li>
<li><p>Click <strong>Link to Credential</strong> for the <strong>Bosh Commandline Credentials</strong>.</p></li>
<li><p>From the plaintext file that opens, record the values for the following:</p>

<ul>
<li><code>BOSH_CLIENT</code></li>
<li><code>BOSH_CLIENT_SECRET</code></li>
<li><code>BOSH_CA_CERT</code></li>
<li><code>BOSH_ENVIRONMENT</code></li>
</ul></li>
<li><p>From the BOSH CLI, view the name of the BOSH deployment for Tanzu SQL for VMs by running:</p>
<code>bosh deployments</code>

<p>Record the name of the BOSH deployment.</p></li>
<li><p>SSH into your Ops Manager VM by doing the procedures in
<a href="https://docs.pivotal.io/pivotalcf/customizing/trouble-advanced.html#gather">Gather Credential and IP Address Information</a>
and <a href="https://docs.pivotal.io/pivotalcf/customizing/trouble-advanced.html#ssh">SSH into Ops Manager</a>.</p></li>
<li><p>File transfer or copy-paste the <code>download-logs</code> script to a working directory on the Ops Manager VM.</p></li>
<li><p>Set local environment variables to the same BOSH variable values that you recorded earlier,
including <code>BOSH_DEPLOYMENT</code> for the deployment name.
<br><br>
For example:
<pre class="terminal">$ BOSH_CLIENT=ops_manager \
  BOSH_CLIENT_SECRET=a123bc-E_4Ke3fb-gImbl3xw4a7meW0rY
  BOSH_CA_CERT=/var/tempest/workspaces/default/root_ca_certificate \
  BOSH_ENVIRONMENT=10.0.0.5 \
  BOSH_DEPLOYMENT=pivotal-mysql-14c4</pre>
  </p></li>
<li><p>Run the <code>download-logs</code> script by running:</p>
<code>./download-logs -o .</code>

<p>The script saves a compressed file of logs combined from all Tanzu SQL for VMs VMs.
The filename has the form <code>TIMESTAMP-mysql-logs.tar.gz.gpg</code>.</p></li>
</ol>


##  <a id="tools"></a>  Tools for Troubleshooting

The troubleshooting techniques described above use the following tools.

### <a id="download-logs"></a>download-logs

`download-logs` is a script that you can run from your <%= vars.ops_manager %> VM to aggregate
logs from your <%= vars.product_short %> cluster nodes, proxies, and, with highly available clusters,
the jumpbox VM.

To use the `download-logs` script:

1. Download and unzip the `download-logs` script from
[<%= vars.product_network %>](https://network.pivotal.io/products/pivotal-mysql).

1. From the <%= vars.ops_manager %> Installation Dashboard, navigate to **BOSH Director** > **Credentials**.

1. Click **Link to Credential** for the **Bosh Commandline Credentials**.

4. From the plaintext file that opens, record the values for the following:
  + `BOSH_CLIENT`
  + `BOSH_CLIENT_SECRET`
  + `BOSH_CA_CERT`
  + `BOSH_ENVIRONMENT`

1. From the BOSH CLI, view the name of the BOSH deployment for <%= vars.product_short %> by running:

    ```
    bosh deployments
    ```
    Record the name of the BOSH deployment.

1. SSH into your <%= vars.ops_manager %> VM by doing the procedures in
[Gather Credential and IP Address Information](https://docs.vmware.com/en/VMware-Tanzu-Operations-Manager/2.10/vmware-tanzu-ops-manager/install-trouble-advanced.html#gather-credential-and-ip-address-information-1)
and [Log in to the <%= vars.ops_manager %> VM with SSH](https://docs.vmware.com/en/VMware-Tanzu-Operations-Manager/2.10/vmware-tanzu-ops-manager/install-trouble-advanced.html#log-in-to-the-ops-manager-vm-with-ssh-2).

1. File transfer or copy-paste the `download-logs` script to a working directory on the <%= vars.ops_manager %> VM.

1. Set local environment variables to the same BOSH variable values that you recorded earlier,
including `BOSH_DEPLOYMENT` for the deployment name.

    For example:
    <pre class="terminal">$ BOSH\_CLIENT=ops\_manager \
      BOSH\_CLIENT\_SECRET=a123bc-E_4Ke3fb-gImbl3xw4a7meW0rY
      BOSH\_CA\_CERT=/var/tempest/workspaces/default/root\_ca\_certificate \
      BOSH\_ENVIRONMENT=10.0.0.5 \
      BOSH\_DEPLOYMENT=pivotal-mysql-14c4</pre>

1. Run the `download-logs` script by running:

    ```
    ./download-logs -o .
    ```

    The script saves a compressed file of logs combined from all <%= vars.product_short %> VMs.
    The filename has the form `TIMESTAMP-mysql-logs.tar.gz.gpg`.

###  <a id="mysql-diag"></a> mysql-diag

The `mysql-diag` tools outputs the current status of a highly available (HA) <%= vars.product_short %> cluster
and suggests recovery actions if the cluster fails.

For more information, see [Running mysql-diag](./mysql-diag.html).

## <a id="kb"></a> Knowledge Base (Community)

<%= partial '/services-tshoot/tshoot-kb' %>


##  <a id="support"></a>  File a Support Ticket

<%= partial '/services-tshoot/tshoot-support' %>
